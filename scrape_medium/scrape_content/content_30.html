<blockquote class="fn fo fp"><p id="2657" class="fq fr dc fs ft b fu fv fw fx fy fz ga gb gc gd ge cu">Do you want to prove a bit of coding helps in the Humanities? Easy!</p></blockquote><p id="bbfb" class="fq fr dc bk ft b fu fv fw fx fy fz ga gb gc gd ge gf cu"><span class="r gg gh gi gj gk gl gm gn go gp">We</span> all use Google a lot in our research, what if you can store the links you get from search results? This looks like a super-easy task. It takes a second to figure out the steps you need to perform <em class="fs">by hand</em>: access Google, perform the search, get results, save data, move to the next page, iterate if needed.</p><p id="2845" class="fq fr dc bk ft b fu fv fw fx fy fz ga gb gc gd ge cu">Plus the “extract the link” is quite a popular feature in variaty of packages that perform webscraping, you there should be a lot of documentation annd tutorials out there. Even better: the script we want to build is helpful for some colleagues (we’ll work with <strong class="ft gq">Python</strong> here).</p><p id="95d8" class="fq fr dc bk ft b fu fv fw fx fy fz ga gb gc gd ge cu">It looks like that’s an eay task to learn some new features of a library by putting it in practice. Further, it proves the point of <strong class="ft gq">coding helps in the humanities</strong>.</p><p id="ce3d" class="fq fr dc bk ft b fu fv fw fx fy fz ga gb gc gd ge cu">Cool, so just go. It won’t take long, right? Spoiler: it was not that easy (hence the post).</p><figure class="gs gt gu gv gw gx cl cm paragraph-image"><div class="cl cm gr"><div class="hd r gp he"><div class="hf r"><div class="gy gz cp t u ha ak ei hb hc"><img class="cp t u ha ak hg hh hi" src="https://miro.medium.com/max/60/1*wgmjZE_Ex0XhiMLPqLvsDw.png?q=20" width="640" height="513" role="presentation"></div><img class="gy gz cp t u ha ak hj" width="640" height="513" role="presentation"><noscript><img class="cp t u ha ak" src="https://miro.medium.com/max/1280/1*wgmjZE_Ex0XhiMLPqLvsDw.png" width="640" height="513" role="presentation"></noscript></div></div></div><figcaption class="bo eh hk hl hm cn cl cm hn ho bj eg">[SPOILER: but we’ll make it a yes. Image by <a href="https://pixabay.com/users/GDJ-1086657/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=2069850" class="at cg hp hq hr hs" target="_blank" rel="noopener nofollow">Gordon Johnson</a> from <a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=2069850" class="at cg hp hq hr hs" target="_blank" rel="noopener nofollow">Pixabay</a>]</figcaption></figure><section class="cu cv cw cx cy"><div class="n p"><div class="ac ae af ag ah cz aj ak"><h1 id="8b78" class="ic id dc bk bj ie de if dg ig ih ii ij ik il im in">The Basic Idea: Requests and BeautifulSoup</h1><p id="9120" class="fq fr dc bk ft b fu io fw ip fy iq ga ir gc is ge cu">The project outline is easy to map and close to what we would do by hand:</p><ol class=""><li id="a0ca" class="fq fr dc bk ft b fu fv fw fx fy fz ga gb gc gd ge it iu iv">reach a search engine;</li><li id="7dea" class="fq fr dc bk ft b fu iw fw ix fy iy ga iz gc ja ge it iu iv">query it;</li><li id="c28b" class="fq fr dc bk ft b fu iw fw ix fy iy ga iz gc ja ge it iu iv">get the results of the query;</li><li id="72ac" class="fq fr dc bk ft b fu iw fw ix fy iy ga iz gc ja ge it iu iv">extract all the links;</li><li id="0488" class="fq fr dc bk ft b fu iw fw ix fy iy ga iz gc ja ge it iu iv">save them;</li><li id="e8a8" class="fq fr dc bk ft b fu iw fw ix fy iy ga iz gc ja ge it iu iv">move to the next page;</li><li id="0a78" class="fq fr dc bk ft b fu iw fw ix fy iy ga iz gc ja ge it iu iv">rinse and repeat.</li></ol><p id="ed29" class="fq fr dc bk ft b fu fv fw fx fy fz ga gb gc gd ge cu">Step 4 looks like the most scary one. We’ll have to inspect the html and get the right tag. But that’s part of the fun. Ok, there are issues lurking here like “how do I find out when I run out of results?”. But we can agree to have a fixed set of pages scraped or even stop a the first one.</p><p id="5953" class="fq fr dc bk ft b fu fv fw fx fy fz ga gb gc gd ge cu">Armed with <strong class="ft gq">requests</strong> and <strong class="ft gq">BeautifulSoup</strong> library (if you don’t have them, get the instruction for installation <a href="https://2.python-requests.org/en/master/user/install/" class="at cg hp hq hr hs" target="_blank" rel="noopener nofollow">here</a> and <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-beautiful-soup" class="at cg hp hq hr hs" target="_blank" rel="noopener nofollow">here</a>, respectively) we begin our journey with some standard imports:</p><pre class="gs gt gu gv gw jb jc jd"><span id="4556" class="je id dc bk jf b eh jg jh r ji"><strong class="jf gq">import</strong> requests<br><strong class="jf gq">from</strong> bs4 <strong class="jf gq">import</strong> BeautifulSoup <strong class="jf gq">as</strong> bs</span></pre><p id="7b08" class="fq fr dc bk ft b fu fv fw fx fy fz ga gb gc gd ge cu">Next, we build our request to a search engige (Google here). To do that we note that all queries on Google have the url that goes as: ‘<a href="https://www.google.com/search?q=" class="at cg hp hq hr hs" target="_blank" rel="noopener nofollow"><em class="fs">https://www.google.com/search?q=</em></a>’ + ‘something to query’.</p><p id="f57e" class="fq fr dc bk ft b fu fv fw fx fy fz ga gb gc gd ge cu">As we don’t want to keep typing our query as an input, we’ll hard code it, i.e. search ‘Goofy’. Then, we check the status of our request to make sure everything is ok when we access the page.</p><pre class="gs gt gu gv gw jb jc jd"><span id="7ed4" class="je id dc bk jf b eh jg jh r ji"><strong class="jf gq">import</strong> requests<br><strong class="jf gq">from</strong> bs4 <strong class="jf gq">import</strong> BeautifulSoup <strong class="jf gq">as</strong> bs</span><span id="971f" class="je id dc bk jf b eh jj jk jl jm jn jh r ji"><em class="fs">#search for our term with requests</em><br>searchreq = requests.get('https://www.google.com/search?q=Goofy')<br><em class="fs"><br>#ensure it works</em><br>searchreq.raise_for_status()</span></pre><p id="a783" class="fq fr dc bk ft b fu fv fw fx fy fz ga gb gc gd ge cu">If you want to input a different query everytime (i.e. not to hard code it) you may go with something like this:</p><pre class="gs gt gu gv gw jb jc jd"><span id="e446" class="je id dc bk jf b eh jg jh r ji"><strong class="jf gq">import</strong> requests<br><strong class="jf gq">from</strong> bs4 <strong class="jf gq">import</strong> BeautifulSoup <strong class="jf gq">as</strong> bs</span><span id="48b7" class="je id dc bk jf b eh jj jk jl jm jn jh r ji"><em class="fs"># ask the user what to search</em><br>query = input('What do you want to search?')</span><span id="4c84" class="je id dc bk jf b eh jj jk jl jm jn jh r ji"><em class="fs">#search for our term with requests</em><br>searchreq = requests.get('https://www.google.com/search?q=' + query)</span><span id="66a7" class="je id dc bk jf b eh jj jk jl jm jn jh r ji"><em class="fs">#ensure it works</em><br>searchreq.raise_for_status()</span></pre><h1 id="03b5" class="ic id dc bk bj ie de jo dg jp ih jq ij jr il js in">Getting the Links</h1><p id="f406" class="fq fr dc bk ft b fu io fw ip fy iq ga ir gc is ge cu">We have done tasks 1, 2 and 3 from our sketch. Now comes the tricky part. We need to isolate the links that Google gives us. This means we need to create a BeautifulSoup object for each page returning the search results (i.e. what we called <strong class="ft gq">searchreq</strong>) and process them with BeautifulSoup.</p><p id="4b6e" class="fq fr dc bk ft b fu fv fw fx fy fz ga gb gc gd ge cu">We follow the standard practice and call this object ‘soup’. We also specify it’s html that we want to parse. Then in ‘results’ we are going to use our soup object to return what we need and print it. That’s what we add to our code:</p><pre class="gs gt gu gv gw jb jc jd"><span id="d0bf" class="je id dc bk jf b eh jg jh r ji"><em class="fs"># creating the Beautiful Soup object to parse html <br></em>soup = bs(searchreq.text, 'html.parser')</span><span id="6039" class="je id dc bk jf b eh jj jk jl jm jn jh r ji"><em class="fs">#apply a find all method on our soup object to get the result</em><br>results = soup.find_all() <em class="fs">#but wait, what to we have to search?</em></span><span id="cc09" class="je id dc bk jf b eh jj jk jl jm jn jh r ji"><em class="fs">#print them and be happy (if it works)</em><br>print(results)</span><span id="e591" class="je id dc bk jf b eh jj jk jl jm jn jh r ji"><em class="fs">#SPOILER: it won't</em></span></pre><h1 id="03c0" class="ic id dc bk bj ie de jo dg jp ih jq ij jr il js in">Scraping the Links</h1><p id="7f06" class="fq fr dc bk ft b fu io fw ip fy iq ga ir gc is ge cu">To scrape the links we need to tell BeautifulSoup what we need it to extract. To find this out, we call the inspector mode from our web browser on one of the search results (right click and select inspect on Chrome).</p><p id="798f" class="fq fr dc bk ft b fu fv fw fx fy fz ga gb gc gd ge cu">From there we play a game of:</p><ol class=""><li id="62fd" class="fq fr dc bk ft b fu fv fw fx fy fz ga gb gc gd ge it iu iv">finding the items we need;</li><li id="18df" class="fq fr dc bk ft b fu iw fw ix fy iy ga iz gc ja ge it iu iv">extracting patterns or regularities for the items we care about (i.e. the links);</li><li id="0330" class="fq fr dc bk ft b fu iw fw ix fy iy ga iz gc ja ge it iu iv">catch them all.</li></ol><figure class="gs gt gu gv gw gx cl cm paragraph-image"><div class="ju jv gp jw ak"><div class="cl cm jt"><div class="hd r gp he"><div class="jx r"><div class="gy gz cp t u ha ak ei hb hc"><img class="cp t u ha ak hg hh hi" src="https://miro.medium.com/max/60/1*NBLLEGDxvYM3iQOBpKih_Q.jpeg?q=20" width="1280" height="853" role="presentation"></div><img class="gy gz cp t u ha ak hj" width="1280" height="853" role="presentation"><noscript><img class="cp t u ha ak" src="https://miro.medium.com/max/2560/1*NBLLEGDxvYM3iQOBpKih_Q.jpeg" width="1280" height="853" role="presentation"></noscript></div></div></div></div><figcaption class="bo eh hk hl hm cn cl cm hn ho bj eg">[Sorry, this has to happen — Photo by <a href="https://www.pexels.com/@carocastilla?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" class="at cg hp hq hr hs" target="_blank" rel="noopener nofollow">Carolina Castilla Arias </a>from <a href="https://www.pexels.com/photo/close-up-photo-of-pokemon-pikachu-figurine-1716861/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" class="at cg hp hq hr hs" target="_blank" rel="noopener nofollow">Pexels</a>]</figcaption></figure><p id="b1ee" class="fq fr dc bk ft b fu fv fw fx fy fz ga gb gc gd ge cu">Our first choice might be something like ‘http’, but this is going to catch a lot of extra stuff as well like links that are <strong class="ft gq">not</strong> search results.</p><p id="5289" class="fq fr dc bk ft b fu fv fw fx fy fz ga gb gc gd ge cu">You have to think about HTML patterns and tags. If you look at it (or Google around like crazy), you’ll find out that there’s a nice thing called <strong class="ft gq">div class=“r”</strong> that seems to have what you are looking for.</p><p id="cc7b" class="fq fr dc bk ft b fu fv fw fx fy fz ga gb gc gd ge cu">After a few extra minutes with the BeautifulSoup documentation page, we learn to get them from the soup with: <strong class="ft gq">soup.select(‘.r a’)</strong>.</p><p id="229f" class="fq fr dc bk ft b fu fv fw fx fy fz ga gb gc gd ge cu">So we put all together:</p><pre class="gs gt gu gv gw jb jc jd"><span id="2cd2" class="je id dc bk jf b eh jg jh r ji"><strong class="jf gq">import</strong> requests<br><strong class="jf gq">from</strong> bs4 <strong class="jf gq">import</strong> BeautifulSoup <strong class="jf gq">as</strong> bs<br><em class="fs"># ask the user for a the search</em><br>query = input('What do you want to search?')</span><span id="237b" class="je id dc bk jf b eh jj jk jl jm jn jh r ji"><em class="fs">#search for our term with requests</em><br>searchreq = requests.get('https://www.google.com/search?q=' + query)</span><span id="2bb8" class="je id dc bk jf b eh jj jk jl jm jn jh r ji"><em class="fs">#ensure it works</em><br>searchreq.raise_for_status()</span><span id="be53" class="je id dc bk jf b eh jj jk jl jm jn jh r ji"><em class="fs"># creating the Beautiful Soup object</em><br>soup = bs(searchreq.text, 'html.parser')</span><span id="747a" class="je id dc bk jf b eh jj jk jl jm jn jh r ji"><em class="fs">#apply a find all method on our soup object to get the result</em><br>results = soup.select('.r a')</span><span id="25d5" class="je id dc bk jf b eh jj jk jl jm jn jh r ji">print(results)</span></pre><p id="ee45" class="fq fr dc bk ft b fu fv fw fx fy fz ga gb gc gd ge cu">We are ready to try this out!</p><h1 id="7d9f" class="ic id dc bk bj ie de jo dg jp ih jq ij jr il js in">Stuck: The World Strikes Back</h1><p id="a446" class="fq fr dc bk ft b fu io fw ip fy iq ga ir gc is ge cu"><strong class="ft gq">[]</strong></p><p id="c6e6" class="fq fr dc bk ft b fu fv fw fx fy fz ga gb gc gd ge cu">Exactly, watch that again. A pair of square brackets. That’s our output.</p><p id="6511" class="fq fr dc bk ft b fu fv fw fx fy fz ga gb gc gd ge cu"><strong class="ft gq">[], i.e. </strong>an empty list.</p><p id="4df6" class="fq fr dc bk ft b fu fv fw fx fy fz ga gb gc gd ge cu">That’s our result. This is disappointing. Why is that? What’s happening? Let’s check what’s going on.</p><p id="bdac" class="fq fr dc bk ft b fu fv fw fx fy fz ga gb gc gd ge cu">The first we do is try to print our soup object (if you have Ipython, use the shell). Once we have the soup object printed, we try to search our beloved “r” class, the one we are trying to select with out soup object.</p><p id="4b09" class="fq fr dc bk ft b fu fv fw fx fy fz ga gb gc gd ge cu"><strong class="ft gq">It’s not there!</strong></p><p id="8499" class="fq fr dc bk ft b fu fv fw fx fy fz ga gb gc gd ge cu">This is: <em class="fs">the world getting back on us</em>. In practice, theory is not enough. So, well, <em class="fs">now we can panic</em>. What’s going on? This was supposed to be an easy task.</p><h1 id="c6a7" class="ic id dc bk bj ie de jo dg jp ih jq ij jr il js in">Ways Out</h1><p id="cab4" class="fq fr dc bk ft b fu io fw ip fy iq ga ir gc is ge cu">We start googling more. I went out on Twitter and ask Al Sweigart (the author of <a href="https://automatetheboringstuff.com/" class="at cg hp hq hr hs" target="_blank" rel="noopener nofollow">Automate the Boring Stuff with Python</a>, a book you should check if you are starting out with Python) about it. In fact, one of the programs in the book discusses the task of getting links.</p><p id="be7d" class="fq fr dc bk ft b fu fv fw fx fy fz ga gb gc gd ge cu">Al was kind enough to let me know that’s common practice for Google to obscure its results. That’s why the soup doesn’t match what we looked at. He briefly reminded me there’s life out of Google, so there are chances to be better off searching on different search engines (he suggested duckduckgo).</p><p id="e679" class="fq fr dc bk ft b fu fv fw fx fy fz ga gb gc gd ge cu">That’s <em class="fs">reeeeally</em> important (hence the extra <em class="fs">Es</em>). Now we know the cause of the problem: <strong class="ft gq">the HTML we see on the Google is not the same we get with our request</strong>. And we already have a hint towards a solution: try asking to different search engines.</p><p id="7bf0" class="fq fr dc bk ft b fu fv fw fx fy fz ga gb gc gd ge cu">We can use these new knowledge to build alternative ways.</p><h1 id="6eb3" class="ic id dc bk bj ie de jo dg jp ih jq ij jr il js in">Rethinking the Issue</h1><p id="2b83" class="fq fr dc bk ft b fu io fw ip fy iq ga ir gc is ge cu">We have a new problem. The HTML that delivers our search results is partly out of our control. What can we do? Can we get it like we see? Are there ways around it? This depends on how we want to fight.</p><h1 id="08ad" class="ic id dc bk bj ie de jo dg jp ih jq ij jr il js in">1. Ways Around: Different Search Engines</h1><p id="618e" class="fq fr dc bk ft b fu io fw ip fy iq ga ir gc is ge cu">The first option is to circumvent the problem: we pick a different search engine. In practice, we go on <em class="fs">Wikipedia</em> and asks for search engines names. We then figure out how the query is asked and hope that the links extraction phase stays the same.</p><p id="5351" class="fq fr dc bk ft b fu fv fw fx fy fz ga gb gc gd ge cu">Assuming this, that doesn’t look as a costly option. And we hope one of the engines gives us the same html we can inspect.</p><h1 id="a216" class="ic id dc bk bj ie de jo dg jp ih jq ij jr il js in">2. No Way(s): We Fight!</h1><p id="7b78" class="fq fr dc bk ft b fu io fw ip fy iq ga ir gc is ge cu">We know what we want to get. Despite the HTML tags being different, we know the links are still there. What about extracting them through <a href="https://docs.python.org/3/howto/regex.html" class="at cg hp hq hr hs" target="_blank" rel="noopener nofollow"><strong class="ft gq">regular expressions</strong></a>? It will be difficult and maybe sub-optmial, but rather than risking to fight again with HTML obfuscation, etc. we can tackle the issue once and forever.</p><p id="ef46" class="fq fr dc bk ft b fu fv fw fx fy fz ga gb gc gd ge cu">We’ll write a regular expression extracting all that <em class="fs">http-something</em>. We can predict we will:</p><ul class=""><li id="266a" class="fq fr dc bk ft b fu fv fw fx fy fz ga gb gc gd ge jy iu iv">have double results or even more copies (which we’ll exclude by way of making a <strong class="ft gq">set</strong> out of our results)</li><li id="c76c" class="fq fr dc bk ft b fu iw fw ix fy iy ga iz gc ja ge jy iu iv">have some bad results (like links to you Google account; or extra non-search related links).</li></ul><p id="9725" class="fq fr dc bk ft b fu fv fw fx fy fz ga gb gc gd ge cu">Assuming you can identify the bad links, more links than required might be better than the [empty list] we got before.</p><h1 id="9e15" class="ic id dc bk bj ie de jo dg jp ih jq ij jr il js in">3. Rebuilding: from BeutifulSoup to Selenium</h1><p id="6b65" class="fq fr dc bk ft b fu io fw ip fy iq ga ir gc is ge cu">Maybe we can get around the HTML obfuscation and get the search results in a different way. <strong class="ft gq">Selenium</strong> is another popular Python library that allows us to automate our browsing.</p><p id="acb4" class="fq fr dc bk ft b fu fv fw fx fy fz ga gb gc gd ge cu">Selenium will open the browser for us and then we’ll have a look at the HTML. Should this fail, we may have Selenium inspect the page for us and copy and paste the inspected html.</p><p id="49cb" class="fq fr dc bk ft b fu fv fw fx fy fz ga gb gc gd ge cu">This seems something that can work <em class="fs">in theory</em>. But requires extra efforts.</p><h1 id="373d" class="ic id dc bk bj ie de jo dg jp ih jq ij jr il js in">4. Download the HTML in Different Ways</h1><p id="75bc" class="fq fr dc bk ft b fu io fw ip fy iq ga ir gc is ge cu">We know that obfuscation happens but we do not know how and when. Maybe we can try to download the page and save it on our desktop and operate from there.</p><p id="5950" class="fq fr dc bk ft b fu fv fw fx fy fz ga gb gc gd ge cu">This sounds both simple and complicated. Saving a file, easy. Still, we need to access it properly… Is request the way to go? This requires some extra efforts.</p><h1 id="4bdb" class="ic id dc bk bj ie de jo dg jp ih jq ij jr il js in">To Do:</h1><p id="00f6" class="fq fr dc bk ft b fu io fw ip fy iq ga ir gc is ge cu">Ok, there’s still a problem but the field looks clearer:</p><ul class=""><li id="8723" class="fq fr dc bk ft b fu fv fw fx fy fz ga gb gc gd ge jy iu iv">the different ways need exploring;</li><li id="afc0" class="fq fr dc bk ft b fu iw fw ix fy iy ga iz gc ja ge jy iu iv">code should grow and make it to GitHub.</li></ul></div></div></section><section class="cu cv cw cx cy"><div class="n p"><div class="ac ae af ag ah cz aj ak"><p id="006f" class="fq fr dc bk ft b fu fv fw fx fy fz ga gb gc gd ge cu">(This is an improved and reviewed version of a previous post that appeared here: <a href="http://www.thegui.eu/blog/scraping-links-from-google-part-1.htm" class="at cg hp hq hr hs" target="_blank" rel="noopener nofollow">http://www.thegui.eu/blog/scraping-links-from-google-part-1.htm</a>).</p><p id="f44f" class="fq fr dc bk ft b fu fv fw fx fy fz ga gb gc gd ge cu">This work is carried out as part of a <strong class="ft gq">CAS Fellowship</strong> as <em class="fs">CAS-SEE Rijeka</em>. See more about the Fellowship <a href="http://cas.uniri.hr/cas-see-fellowship-application/" class="at cg hp hq hr hs" target="_blank" rel="noopener nofollow">here.</a></p></div></div></section>