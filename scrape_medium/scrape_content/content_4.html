<figure class="gr gs gt gu gv gw do dp paragraph-image"><div class="gx gy gz ha ak"><div class="do dp gq"><div class="hg r gz hh"><div class="hi r"><div class="hb hc ds t u hd ak cd he hf"><img class="ds t u hd ak hj hk hl" src="https://miro.medium.com/max/60/1*9yn_stb9a0OWJK_Qog6urw.png?q=20" width="1281" height="714" role="presentation"></div><img class="hb hc ds t u hd ak hm" width="1281" height="714" role="presentation"><noscript><img class="ds t u hd ak" src="https://miro.medium.com/max/2562/1*9yn_stb9a0OWJK_Qog6urw.png" width="1281" height="714" role="presentation"></noscript></div></div></div></div></figure><p id="57b2" class="hn ho ef at hp b hq hr hs ht hu hv hw hx hy hz ia dx">What do you do when you can‚Äôt download a website‚Äôs information? You do it by hand? Wow, you‚Äôre brave!</p><p id="e325" class="hn ho ef at hp b hq hr hs ht hu hv hw hx hy hz ia dx">I‚Äôm a web developer, so I‚Äôm way too lazy to do things manually üôÇ</p><p id="2c64" class="hn ho ef at hp b hq hr hs ht hu hv hw hx hy hz ia dx">If you‚Äôre about to scrape data for the first time, go ahead and read <a href="https://captaindata.co/blog/how-scrape-website/" class="dc by ib ic id ie" target="_blank" rel="noopener nofollow">How To Scrape A Website</a>. You can also read a small intro about <a href="https://captaindata.co/web-scraping" class="dc by ib ic id ie" target="_blank" rel="noopener nofollow">web scraping</a>.</p><p id="e2fa" class="hn ho ef at hp b hq hr hs ht hu hv hw hx hy hz ia dx">Today, let‚Äôs say that you need to enrich your CRM with company data.</p><p id="9c0e" class="hn ho ef at hp b hq hr hs ht hu hv hw hx hy hz ia dx">To make it interesting for you, we will scrape <a href="https://angel.co/" class="dc by ib ic id ie" target="_blank" rel="noopener nofollow">Angel List</a>.</p><p id="e566" class="hn ho ef at hp b hq hr hs ht hu hv hw hx hy hz ia dx">More specifically, we‚Äôll scrape <a href="https://angel.co/uber" class="dc by ib ic id ie" target="_blank" rel="noopener nofollow">Uber‚Äôs company profile</a>.</p><blockquote class="if ig ih"><p id="3cfc" class="hn ho ef ii hp b hq hr hs ht hu hv hw hx hy hz ia dx"><em class="at">Please scrape responsibly!</em></p></blockquote><h1 id="9e90" class="ij ik ef at as il eh im ej in io ip iq ir is it iu">Getting started</h1><p id="98e9" class="hn ho ef at hp b hq iv hs iw hu ix hw iy hy iz ia dx">Before starting to code, be sure to have <strong class="hp ja">Python 3</strong> installed, as we won‚Äôt cover it here. Chances are you already have it installed.</p><p id="6ed7" class="hn ho ef at hp b hq hr hs ht hu hv hw hx hy hz ia dx">You also need <code class="hh jb jc jd je b">pip</code>, a package management tool for Python.</p><pre class="gr gs gt gu gv jf jg cm"><span id="d3a6" class="jh ik ef at je b fi ji jj r jk">easy_install pip</span></pre><p id="9a42" class="hn ho ef at hp b hq hr hs ht hu hv hw hx hy hz ia dx">The full code and dependencies are <a href="https://github.com/captaindatatech/scraping-examples/blob/master/scripts/Angel%20List%20Company%20Info.py" class="dc by ib ic id ie" target="_blank" rel="noopener nofollow">available here</a>.</p><p id="4f5a" class="hn ho ef at hp b hq hr hs ht hu hv hw hx hy hz ia dx">We‚Äôll be using BeautifulSoup, a standard Python scraping library.</p><pre class="gr gs gt gu gv jf jg cm"><span id="c896" class="jh ik ef at je b fi ji jj r jk">pip install BeautifulSoup4</span></pre><p id="3579" class="hn ho ef at hp b hq hr hs ht hu hv hw hx hy hz ia dx">You could also create a <a href="https://realpython.com/python-virtual-environments-a-primer/" class="dc by ib ic id ie" target="_blank" rel="noopener nofollow">virtual environment</a> and install all the dependencies inside the requirements.txt file:</p><pre class="gr gs gt gu gv jf jg cm"><span id="1c32" class="jh ik ef at je b fi ji jj r jk">pip install -r requirements.txt</span></pre><h1 id="3be1" class="ij ik ef at as il eh im ej in io ip iq ir is it iu">Inspecting Content</h1><p id="9900" class="hn ho ef at hp b hq iv hs iw hu ix hw iy hy iz ia dx">Open <a href="https://angel.co/uber" class="dc by ib ic id ie" target="_blank" rel="noopener nofollow">https://angel.co/uber</a> in your web browser (I recommend using Chrome).</p><p id="8f78" class="hn ho ef at hp b hq hr hs ht hu hv hw hx hy hz ia dx">Right-click and open your browser‚Äôs inspector.</p><figure class="gr gs gt gu gv gw do dp paragraph-image"><div class="do dp jl"><div class="hg r gz hh"><div class="jm r"><div class="hb hc ds t u hd ak cd he hf"><img class="ds t u hd ak hj hk hl" src="https://miro.medium.com/max/60/1*iVZ3ZDXCq7cJ3VeRZnw-1w.png?q=20" width="335" height="244" role="presentation"></div><img class="hb hc ds t u hd ak hm" width="335" height="244" role="presentation"><noscript><img class="ds t u hd ak" src="https://miro.medium.com/max/670/1*iVZ3ZDXCq7cJ3VeRZnw-1w.png" width="335" height="244" role="presentation"></noscript></div></div></div><figcaption class="ax fi jn jo jp dq do dp jq jr as cx">Sorry, it‚Äôs in French!</figcaption></figure><p id="38d5" class="hn ho ef at hp b hq hr hs ht hu hv hw hx hy hz ia dx">Hover your cursor on the description.</p><figure class="gr gs gt gu gv gw do dp paragraph-image"><div class="gx gy gz ha ak"><div class="do dp js"><div class="hg r gz hh"><div class="jt r"><div class="hb hc ds t u hd ak cd he hf"><img class="ds t u hd ak hj hk hl" src="https://miro.medium.com/max/60/1*9hXctTThkIj6AiB7HNXMRA.png?q=20" width="2508" height="796" role="presentation"></div><img class="hb hc ds t u hd ak hm" width="2508" height="796" role="presentation"><noscript><img class="ds t u hd ak" src="https://miro.medium.com/max/5016/1*9hXctTThkIj6AiB7HNXMRA.png" width="2508" height="796" role="presentation"></noscript></div></div></div></div></figure><p id="e2a0" class="hn ho ef at hp b hq hr hs ht hu hv hw hx hy hz ia dx">This example is pretty straightforward: you want the <code class="hh jb jc jd je b"><strong class="hp ja">&lt;h2&gt;</strong></code> tag with the <strong class="hp ja">js-startup_high_concept</strong> class.</p><p id="7ee7" class="hn ho ef at hp b hq hr hs ht hu hv hw hx hy hz ia dx">This would be the unique location of our data thanks to the <code class="hh jb jc jd je b">class</code> tags.</p><h1 id="7993" class="ij ik ef at as il eh im ej in io ip iq ir is it iu">Extracting Data</h1><p id="2618" class="hn ho ef at hp b hq iv hs iw hu ix hw iy hy iz ia dx">Let‚Äôs dive right in with a bit of code:</p><pre class="gr gs gt gu gv jf jg cm"><span id="9259" class="jh ik ef at je b fi ji jj r jk"># we'll get back to this <br>headers = {} </span><span id="f5eb" class="jh ik ef at je b fi ju jv jw jx jy jj r jk"># the Uber company page you're about to scrape! <br>company_page = '&lt;https://angel.co/uber&gt;' </span><span id="eb0e" class="jh ik ef at je b fi ju jv jw jx jy jj r jk"># open the page <br>page_request = request.Request(company_page, headers=headers) <br>page = request.urlopen(page_request) </span><span id="b34f" class="jh ik ef at je b fi ju jv jw jx jy jj r jk"># parse the html using beautifulsoup <br>html_content = BeautifulSoup(page, 'html.parser') <br>description = html_content.find('h2', attrs={'class': 'js-startup_high_concept'}) <br>print(description)</span></pre><p id="2334" class="hn ho ef at hp b hq hr hs ht hu hv hw hx hy hz ia dx">Let‚Äôs get into the details:</p><ul class=""><li id="c310" class="hn ho ef at hp b hq hr hs ht hu hv hw hx hy hz ia jz ka kb">We create a variable <strong class="hp ja"><em class="ii">headers</em></strong> (more on this very soon)</li><li id="cce6" class="hn ho ef at hp b hq kc hs kd hu ke hw kf hy kg ia jz ka kb">The <strong class="hp ja"><em class="ii">company_page</em></strong> variable is the page we‚Äôre targeting</li><li id="20ee" class="hn ho ef at hp b hq kc hs kd hu ke hw kf hy kg ia jz ka kb">Then we build our request. We inject the <strong class="hp ja"><em class="ii">company_page</em></strong> and <strong class="hp ja"><em class="ii">headers</em></strong> variable inside the <strong class="hp ja">Request</strong> object. Then we open the url with the parameterized request.</li><li id="3246" class="hn ho ef at hp b hq kc hs kd hu ke hw kf hy kg ia jz ka kb">We parse the HTML response with BeautifulSoup</li><li id="f715" class="hn ho ef at hp b hq kc hs kd hu ke hw kf hy kg ia jz ka kb">We look for our text content with the <strong class="hp ja"><em class="ii">find()</em></strong> method</li><li id="2178" class="hn ho ef at hp b hq kc hs kd hu ke hw kf hy kg ia jz ka kb">We print our result!</li></ul><p id="d1f7" class="hn ho ef at hp b hq hr hs ht hu hv hw hx hy hz ia dx">Save this as <a href="http://script.py/" class="dc by ib ic id ie" target="_blank" rel="noopener nofollow">script.py</a> and run it in your shell, like this <code class="hh jb jc jd je b">python script.py</code>.</p><p id="7ce3" class="hn ho ef at hp b hq hr hs ht hu hv hw hx hy hz ia dx">You should get the following:</p><pre class="gr gs gt gu gv jf jg cm"><span id="a43e" class="jh ik ef at je b fi ji jj r jk">urllib.error.HTTPError: HTTP Error 403: Forbidden</span></pre><p id="b1b6" class="hn ho ef at hp b hq hr hs ht hu hv hw hx hy hz ia dx">Oh üôÅ What happened?</p><p id="1879" class="hn ho ef at hp b hq hr hs ht hu hv hw hx hy hz ia dx">Well, it seems that AngelList has detected that we are a bot. Clever people!</p><p id="ac96" class="hn ho ef at hp b hq hr hs ht hu hv hw hx hy hz ia dx">Okay, so change the <strong class="hp ja"><em class="ii">headers</em></strong> variable for this one:</p><pre class="gr gs gt gu gv jf jg cm"><span id="1098" class="jh ik ef at je b fi ji jj r jk">headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}</span></pre><p id="d696" class="hn ho ef at hp b hq hr hs ht hu hv hw hx hy hz ia dx">Run the code with <code class="hh jb jc jd je b">python script.py</code>. Now it should be good:</p><pre class="gr gs gt gu gv jf jg cm"><span id="708c" class="jh ik ef at je b fi ji jj r jk">&lt;h2 class="js-startup_high_concept u-fontSize15 u-fontWeight400 u-colorGray3"&gt; The better way to get there &lt;/h2&gt;</span></pre><p id="ba63" class="hn ho ef at hp b hq hr hs ht hu hv hw hx hy hz ia dx">Yeah! Our first piece of data üòÄ</p><p id="48fa" class="hn ho ef at hp b hq hr hs ht hu hv hw hx hy hz ia dx">Want to find the website? Easy:</p><pre class="gr gs gt gu gv jf jg cm"><span id="9856" class="jh ik ef at je b fi ji jj r jk"># we extract the website <br>website = html_content.find('a', attrs={'class': 'company_url'})<br>print(website)</span></pre><p id="3096" class="hn ho ef at hp b hq hr hs ht hu hv hw hx hy hz ia dx">And you get:</p><pre class="gr gs gt gu gv jf jg cm"><span id="97bb" class="jh ik ef at je b fi ji jj r jk">&lt;a class="u-uncoloredLink company_url" href="http://www.uber.com/" rel= nofollow noopener noreferrer" target="_blank"&gt;uber.com&lt;/a&gt;</span></pre><p id="795e" class="hn ho ef at hp b hq hr hs ht hu hv hw hx hy hz ia dx">Ok, but how do I get the <strong class="hp ja">value</strong> of the website?</p><p id="311a" class="hn ho ef at hp b hq hr hs ht hu hv hw hx hy hz ia dx">Easy. Tell the program to extract the <strong class="hp ja">href</strong>:</p><pre class="gr gs gt gu gv jf jg cm"><span id="a1a5" class="jh ik ef at je b fi ji jj r jk">print(website['href'])</span></pre><p id="4fd3" class="hn ho ef at hp b hq hr hs ht hu hv hw hx hy hz ia dx">Make sure to use the <strong class="hp ja">strip()</strong> method, otherwise you‚Äôll have big spaces:</p><pre class="gr gs gt gu gv jf jg cm"><span id="62e7" class="jh ik ef at je b fi ji jj r jk">description = description.text.strip()</span></pre><p id="32f0" class="hn ho ef at hp b hq hr hs ht hu hv hw hx hy hz ia dx">I won‚Äôt cover in detail all the elements you could extract. If you‚Äôre having issues, you can always check <a href="https://devhints.io/xpath" class="dc by ib ic id ie" target="_blank" rel="noopener nofollow">this amazing XPath cheatsheet</a>.</p><h1 id="6a27" class="ij ik ef at as il eh im ej in io ip iq ir is it iu">Save results to CSV</h1><p id="2387" class="hn ho ef at hp b hq iv hs iw hu ix hw iy hy iz ia dx">Pretty useless to print data, right? We should definitely save it!</p><p id="519d" class="hn ho ef at hp b hq hr hs ht hu hv hw hx hy hz ia dx">The Comma-Separated Values format is really a standard for this purpose. You can import it very easily in Excel or Google Sheets.</p><pre class="gr gs gt gu gv jf jg cm"><span id="9b8d" class="jh ik ef at je b fi ji jj r jk">import csv</span></pre><p id="2780" class="hn ho ef at hp b hq hr hs ht hu hv hw hx hy hz ia dx">Add the following lines:</p><pre class="gr gs gt gu gv jf jg cm"><span id="8d3b" class="jh ik ef at je b fi ji jj r jk"># open a csv with the append (a) parameter <br>with open('angel.csv', 'a') as csv_file: <br>    writer = csv.writer(csv_file) <br>    writer.writerow([description, website])</span></pre><p id="290c" class="hn ho ef at hp b hq hr hs ht hu hv hw hx hy hz ia dx">What you get is a single line of data. Since we told the program to append every result, new lines won‚Äôt erase previous results.</p><h1 id="78b3" class="ij ik ef at as il eh im ej in io ip iq ir is it iu">Check out the whole script</h1><p id="7128" class="hn ho ef at hp b hq iv hs iw hu ix hw iy hy iz ia dx">The script is <a href="https://github.com/captaindatatech/scraping-examples/blob/master/scripts/Angel%20List%20Company%20Info.py" class="dc by ib ic id ie" target="_blank" rel="noopener nofollow">available here</a>.</p><div class="kh ki kj kk kl km"><a href="https://github.com/captaindatatech/scraping-examples/blob/master/scripts/Angel%20List%20Company%20Info.py" rel="noopener nofollow"><div class="kp n ap"><div class="kq n dr p kr ks"><h2 class="as il kt au ef"><div class="cd kn fk fl ko fn">captaindatatech/scraping-examples</div></h2><div class="ku r"><h3 class="as cx fi au ax"><div class="cd kn fk fl ko fn">Various Web Scraping Examples. Checkout how to scrape Angel List Company Info in our github.</div></h3></div></div><div class="kv r"><div class="kw r kx ky kz kv la lb lc"></div></div></div></a></div><h1 id="9606" class="ij ik ef at as il eh im ej in io ip iq ir is it iu">Conclusion</h1><p id="eead" class="hn ho ef at hp b hq iv hs iw hu ix hw iy hy iz ia dx">It wasn‚Äôt that hard, right?</p><p id="1803" class="hn ho ef at hp b hq hr hs ht hu hv hw hx hy hz ia dx">We covered a very basic example. You could also add multiple pages and parse them inside a for loop.</p><p id="ac44" class="hn ho ef at hp b hq hr hs ht hu hv hw hx hy hz ia dx">Remember how we got blocked by the website‚Äôs security and resolved this by adding a custom User-Agent? We wrote a small paper about <a href="https://captaindata.co/blog/anti-scraping/" class="dc by ib ic id ie" target="_blank" rel="noopener nofollow">anti-scraping</a> techniques. It‚Äôll help you understand how websites try to block bots.</p><p id="b17d" class="hn ho ef at hp b hq hr hs ht hu hv hw hx hy hz ia dx">If you feel like web scraping is too difficult for you or you‚Äôre getting blocked, you can always <a href="https://captaindata.co/contact" class="dc by ib ic id ie" target="_blank" rel="noopener nofollow">contact us</a>!</p><p id="117d" class="hn ho ef at hp b hq hr hs ht hu hv hw hx hy hz ia dx"><a href="https://captaindata.co/api/angellist-company-profile/" class="dc by ib ic id ie" target="_blank" rel="noopener nofollow">You can also use a more advanced version of this script on our platform</a>.</p><section class="dx dy dz ea eb"><div class="n p"><div class="ac ae af ag ah ec aj ak"><p id="e200" class="hn ho ef at hp b hq hr hs ht hu hv hw hx hy hz ia dx"><em class="ii">Originally published at </em><a href="https://captaindata.co/blog/how-scrape-websites-python-beautifulsoup/" class="dc by ib ic id ie" target="_blank" rel="noopener nofollow"><em class="ii">captaindata.co</em></a><em class="ii"> on November 8, 2018.</em></p></div></div></section>